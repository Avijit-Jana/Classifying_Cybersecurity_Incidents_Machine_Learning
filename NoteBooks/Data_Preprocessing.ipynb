{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3qbE-4ZdtY7N",
    "outputId": "150e2d3c-afbb-46e9-a049-df0f1e14daeb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../Dataset/GUIDE_Train.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " Id                          0\n",
      "OrgId                       0\n",
      "IncidentId                  0\n",
      "AlertId                     0\n",
      "Timestamp                   0\n",
      "DetectorId                  0\n",
      "AlertTitle                  0\n",
      "Category                    0\n",
      "MitreTechniques       5468386\n",
      "IncidentGrade           51340\n",
      "ActionGrouped         9460773\n",
      "ActionGranular        9460773\n",
      "EntityType                  0\n",
      "EvidenceRole                0\n",
      "DeviceId                    0\n",
      "Sha256                      0\n",
      "IpAddress                   0\n",
      "Url                         0\n",
      "AccountSid                  0\n",
      "AccountUpn                  0\n",
      "AccountObjectId             0\n",
      "AccountName                 0\n",
      "DeviceName                  0\n",
      "NetworkMessageId            0\n",
      "EmailClusterId        9420025\n",
      "RegistryKey                 0\n",
      "RegistryValueName           0\n",
      "RegistryValueData           0\n",
      "ApplicationId               0\n",
      "ApplicationName             0\n",
      "OAuthApplicationId          0\n",
      "ThreatFamily          9441956\n",
      "FileName                    0\n",
      "FolderPath                  0\n",
      "ResourceIdName              0\n",
      "ResourceType          9509762\n",
      "Roles                 9298686\n",
      "OSFamily                    0\n",
      "OSVersion                   0\n",
      "AntispamDirection     9339535\n",
      "SuspicionLevel        8072708\n",
      "LastVerdict           7282572\n",
      "CountryCode                 0\n",
      "State                       0\n",
      "City                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identify missing values\n",
    "print(\"Missing Values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_threshold = 0.5  # set the threshold for missing values\n",
    "\n",
    "# 1. Remove columns with more than 50% of missing values\n",
    "missing_percentage = df.isnull().mean()\n",
    "columns_to_drop = missing_percentage[missing_percentage > missing_threshold].index\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                        0\n",
       "OrgId                     0\n",
       "IncidentId                0\n",
       "AlertId                   0\n",
       "Timestamp                 0\n",
       "DetectorId                0\n",
       "AlertTitle                0\n",
       "Category                  0\n",
       "IncidentGrade         51340\n",
       "EntityType                0\n",
       "EvidenceRole              0\n",
       "DeviceId                  0\n",
       "Sha256                    0\n",
       "IpAddress                 0\n",
       "Url                       0\n",
       "AccountSid                0\n",
       "AccountUpn                0\n",
       "AccountObjectId           0\n",
       "AccountName               0\n",
       "DeviceName                0\n",
       "NetworkMessageId          0\n",
       "RegistryKey               0\n",
       "RegistryValueName         0\n",
       "RegistryValueData         0\n",
       "ApplicationId             0\n",
       "ApplicationName           0\n",
       "OAuthApplicationId        0\n",
       "FileName                  0\n",
       "FolderPath                0\n",
       "ResourceIdName            0\n",
       "OSFamily                  0\n",
       "OSVersion                 0\n",
       "CountryCode               0\n",
       "State                     0\n",
       "City                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aviji\\AppData\\Local\\Temp\\ipykernel_12056\\3449365735.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['IncidentGrade'].fillna(df['IncidentGrade'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# fill missing values with the mode of the column\n",
    "df['IncidentGrade'].fillna(df['IncidentGrade'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "df.drop_duplicates(inplace=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing outliers: (8970539, 35)\n",
      "After removing outliers: (4910238, 35)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore    # importing the zscore function\n",
    "import numpy as np                # importing the numpy library \n",
    "\n",
    "# function to remove outliers\n",
    "def remove_outliers(df, threshold=3):\n",
    "    numerical_df = df.select_dtypes(include=[np.number])    # Select only numerical columns\n",
    "    z_scores = np.abs((numerical_df - numerical_df.mean()) / numerical_df.std())    # calculating the zscore\n",
    "\n",
    "    # Filter out rows with Z-scores above the threshold in any column\n",
    "    df_clean = df[(z_scores < threshold).all(axis=1)].copy()\n",
    "    return df_clean     # returning the dataframe\n",
    "\n",
    "print(\"Before removing outliers:\", df.shape)    # printing the shape of the dataframe\n",
    "\n",
    "# Remove outliers using Z-score\n",
    "df = remove_outliers(df)  \n",
    "\n",
    "print(\"After removing outliers:\", df.shape)             # printing the shape of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate categorical and numerical columns\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_columns.remove('IncidentGrade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant Features: ['RegistryValueName', 'RegistryValueData']\n"
     ]
    }
   ],
   "source": [
    "constant_features = [col for col in numerical_columns if df[col].nunique() == 1]    # finding the constant features\n",
    "print(\"Constant Features:\", constant_features)\n",
    "df.drop(columns=constant_features, inplace=True)    # dropping the constant features\n",
    "numerical_columns = df.select_dtypes(include=[np.number]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Features Kept: ['Id', 'OrgId', 'IncidentId', 'AlertId', 'DetectorId', 'AlertTitle', 'DeviceId', 'Sha256', 'IpAddress', 'Url', 'AccountSid', 'AccountUpn', 'AccountObjectId', 'AccountName', 'DeviceName', 'NetworkMessageId', 'ApplicationId', 'ApplicationName', 'FileName', 'FolderPath', 'ResourceIdName', 'CountryCode', 'State', 'City']\n",
      "Numerical Features Dropped: ['RegistryKey', 'OAuthApplicationId', 'OSFamily', 'OSVersion']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_classif, chi2\n",
    "\n",
    "target = 'IncidentGrade'    # target column\n",
    "\n",
    "# Perform ANOVA test (f_classif)\n",
    "anova_scores, p_values = f_classif(df[numerical_columns], df[target])\n",
    "significance_level = 0.05   # Set significance threshold for feature selection\n",
    "numerical_to_keep = [num for num, p in zip(numerical_columns, p_values) if p < significance_level]\n",
    "numerical_to_drop = [num for num, p in zip(numerical_columns, p_values) if p >= significance_level]\n",
    "\n",
    "print(f\"Numerical Features Kept: {numerical_to_keep}\")\n",
    "print(f\"Numerical Features Dropped: {numerical_to_drop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=numerical_to_drop, inplace=True)    # dropping unnecessary numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Features Kept: ['Timestamp', 'Category', 'EntityType', 'EvidenceRole']\n",
      "Categorical Features Dropped: []\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "significance_level = 0.05   # setting the significance level\n",
    "categorical_to_keep = []\n",
    "categorical_to_drop = []\n",
    "\n",
    "for col in categorical_columns:\n",
    "    # Create contingency table\n",
    "    contingency_table = pd.crosstab(df[col], df[target])\n",
    "    chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)     # performing the chi2 test\n",
    "    \n",
    "    # Keep or drop feature based on p-value\n",
    "    if p_value < significance_level:\n",
    "        categorical_to_keep.append(col)\n",
    "    else:\n",
    "        categorical_to_drop.append(col)\n",
    "\n",
    "print(f\"Categorical Features Kept: {categorical_to_keep}\")\n",
    "print(f\"Categorical Features Dropped: {categorical_to_drop}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Catagorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp       665569\n",
       "Category            18\n",
       "EntityType          26\n",
       "EvidenceRole         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[categorical_columns].nunique()   # checking the unique values in the categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])   # converting the timestamp column to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Label Encoding\n",
    "le = LabelEncoder()\n",
    "df['Timestamp'] = le.fit_transform(df['Timestamp'])\n",
    "df['EvidenceRole'] = le.fit_transform(df['EvidenceRole'])\n",
    "df['IncidentGrade'] = le.fit_transform(df['IncidentGrade'])\n",
    "df['Category'] = le.fit_transform(df['Category'])   \n",
    "df['EntityType'] = le.fit_transform(df['EntityType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_data.csv', index=False)    # saving the cleaned data to a csv file"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPbqYDMC1kOYxiUNm4o/pqD",
   "mount_file_id": "112yOxEmQ4qFzNIFMqrmQpOIuO5pdNxzf",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
